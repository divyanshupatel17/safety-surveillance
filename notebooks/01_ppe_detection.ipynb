{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# PPE Detection YOLOv8 Training Pipeline\n",
        "\n",
        "Train YOLOv8 model to detect Personal Protective Equipment violations.\n",
        "\n",
        "Model saves to:\n",
        "- Kaggle: /kaggle/working/models/ppe/best.pt\n",
        "- Colab: /content/drive/MyDrive/ppe-models/best.pt\n",
        "- Local: ./models/ppe/best.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step1_title",
      "metadata": {},
      "source": [
        "## Step 1: Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "step1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    IS_COLAB = 'google.colab' in str(get_ipython())\n",
        "except:\n",
        "    IS_COLAB = False\n",
        "\n",
        "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
        "\n",
        "if IS_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_DIR = '/content/drive/MyDrive/ppe-models'\n",
        "    DATASET_PATH = '/content/ppe-dataset'\n",
        "    WORKING_DIR = '/content'\n",
        "elif IS_KAGGLE:\n",
        "    BASE_DIR = '/kaggle/working/models'\n",
        "    DATASET_PATH = '/kaggle/input/ppe-dataset-yolov8'\n",
        "    WORKING_DIR = '/kaggle/working'\n",
        "else:\n",
        "    BASE_DIR = './models'\n",
        "    DATASET_PATH = './datasets/ppe'\n",
        "    WORKING_DIR = '.'\n",
        "\n",
        "MODELS_DIR = os.path.join(BASE_DIR, 'ppe')\n",
        "RESULTS_DIR = os.path.join(WORKING_DIR, 'results')\n",
        "\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Models: {MODELS_DIR}\")\n",
        "print(f\"Dataset: {DATASET_PATH}\")\n",
        "print(f\"Results: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step2_title",
      "metadata": {},
      "source": [
        "## Step 2: Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "step2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "packages = ['ultralytics', 'opencv-python', 'pillow', 'pyyaml']\n",
        "for pkg in packages:\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
        "\n",
        "print('Installed')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step3_title",
      "metadata": {},
      "source": [
        "## Step 3: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "step3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import yaml\n",
        "import json\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "gpu_available = torch.cuda.is_available()\n",
        "device = 0 if gpu_available else 'cpu'\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"GPU: {gpu_available}\")\n",
        "if gpu_available:\n",
        "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"Using: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step4_title",
      "metadata": {},
      "source": [
        "## Step 4: Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "step4",
      "metadata": {},
      "outputs": [],
      "source": [
        "if IS_COLAB:\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'kagglehub'])\n",
        "    import kagglehub\n",
        "    \n",
        "    print('Downloading PPE dataset from Kaggle...')\n",
        "    download_path = kagglehub.dataset_download('shlokraval/ppe-dataset-yolov8')\n",
        "    print(f\"Downloaded to: {download_path}\")\n",
        "    \n",
        "    DATASET_PATH = download_path\n",
        "elif IS_KAGGLE:\n",
        "    print('Using Kaggle input dataset')\n",
        "else:\n",
        "    print('Local mode: ensure dataset is in ./datasets/ppe')\n",
        "\n",
        "print(f\"Dataset path: {DATASET_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step5_title",
      "metadata": {},
      "source": [
        "## Step 5: Configure Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "step5",
      "metadata": {},
      "outputs": [],
      "source": [
        "CLASS_NAMES = {\n",
        "    0: 'helmet',\n",
        "    1: 'vest',\n",
        "    2: 'gloves',\n",
        "    3: 'safety_shoes',\n",
        "    4: 'goggles',\n",
        "    5: 'face_shield'\n",
        "}\n",
        "\n",
        "dataset_exists = os.path.exists(DATASET_PATH)\n",
        "print(f\"Dataset exists: {dataset_exists}\")\n",
        "\n",
        "if dataset_exists:\n",
        "    yaml_path = os.path.join(DATASET_PATH, 'data.yaml')\n",
        "    \n",
        "    if not os.path.exists(yaml_path):\n",
        "        data_config = {\n",
        "            'path': DATASET_PATH,\n",
        "            'train': 'images/train',\n",
        "            'val': 'images/val',\n",
        "            'test': 'images/test',\n",
        "            'nc': len(CLASS_NAMES),\n",
        "            'names': list(CLASS_NAMES.values())\n",
        "        }\n",
        "        with open(yaml_path, 'w') as f:\n",
        "            yaml.dump(data_config, f)\n",
        "        print('Created data.yaml')\n",
        "    else:\n",
        "        print('Found data.yaml')\n",
        "    \n",
        "    for split in ['train', 'val', 'test']:\n",
        "        img_dir = os.path.join(DATASET_PATH, 'images', split)\n",
        "        if os.path.exists(img_dir):\n",
        "            count = len([f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))])\n",
        "            print(f\"{split}: {count} images\")\n",
        "else:\n",
        "    print('Dataset not found')\n",
        "    yaml_path = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step6_title",
      "metadata": {},
      "source": [
        "## Step 6: Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "step6",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_SIZE = 's'\n",
        "\n",
        "model = YOLO(f'yolov8{MODEL_SIZE}.pt')\n",
        "params = sum(p.numel() for p in model.model.parameters()) / 1e6\n",
        "\n",
        "print(f\"Model: YOLOv8{MODEL_SIZE}\")\n",
        "print(f\"Parameters: {params:.2f}M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step7_title",
      "metadata": {},
      "source": [
        "## Step 7: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "step7",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not dataset_exists:\n",
        "    print('Cannot train without dataset')\n",
        "else:\n",
        "    results = model.train(\n",
        "        data=yaml_path,\n",
        "        epochs=20,\n",
        "        imgsz=640,\n",
        "        batch=16,\n",
        "        patience=20,\n",
        "        device=device,\n",
        "        project=os.path.join(WORKING_DIR, 'runs/detect'),\n",
        "        name='ppe_detector',\n",
        "        exist_ok=True,\n",
        "        optimizer='SGD',\n",
        "        lr0=0.01,\n",
        "        lrf=0.01,\n",
        "        momentum=0.937,\n",
        "        weight_decay=0.0005,\n",
        "        warmup_epochs=3,\n",
        "        box=7.5,\n",
        "        cls=0.5,\n",
        "        dfl=1.5,\n",
        "        save=True,\n",
        "        val=True,\n",
        "        plots=True\n",
        "    )\n",
        "    print('Training complete')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step8_title",
      "metadata": {},
      "source": [
        "## Step 8: Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "step8",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not dataset_exists:\n",
        "    print('Cannot evaluate without dataset')\n",
        "else:\n",
        "    best_path = os.path.join(WORKING_DIR, 'runs/detect/ppe_detector/weights/best.pt')\n",
        "    \n",
        "    if os.path.exists(best_path):\n",
        "        eval_model = YOLO(best_path)\n",
        "        val_results = eval_model.val(\n",
        "            data=yaml_path,\n",
        "            imgsz=640,\n",
        "            batch=16,\n",
        "            device=device\n",
        "        )\n",
        "        \n",
        "        print('Performance Metrics:')\n",
        "        if hasattr(val_results, 'box'):\n",
        "            print(f\"mAP50: {val_results.box.map50:.4f}\")\n",
        "            print(f\"mAP50-95: {val_results.box.map:.4f}\")\n",
        "            print(f\"Precision: {val_results.box.mp:.4f}\")\n",
        "            print(f\"Recall: {val_results.box.mr:.4f}\")\n",
        "            \n",
        "            if hasattr(val_results.box, 'ap_class_index'):\n",
        "                print('Per-class mAP50:')\n",
        "                for i, cls_id in enumerate(val_results.box.ap_class_index):\n",
        "                    name = CLASS_NAMES.get(int(cls_id), f\"Class {cls_id}\")\n",
        "                    print(f\"  {name}: {val_results.box.ap50[i]:.4f}\")\n",
        "    else:\n",
        "        print('Best model not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step9_title",
      "metadata": {},
      "source": [
        "## Step 9: Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "step9",
      "metadata": {},
      "outputs": [],
      "source": [
        "source_path = os.path.join(WORKING_DIR, 'runs/detect/ppe_detector/weights/best.pt')\n",
        "final_path = os.path.join(MODELS_DIR, 'best.pt')\n",
        "\n",
        "if os.path.exists(source_path):\n",
        "    shutil.copy2(source_path, final_path)\n",
        "    size_mb = os.path.getsize(final_path) / (1024 * 1024)\n",
        "    \n",
        "    print(f\"Model saved: {final_path}\")\n",
        "    print(f\"Size: {size_mb:.2f} MB\")\n",
        "    \n",
        "    metadata = {\n",
        "        'model_name': f'PPE_YOLOv8{MODEL_SIZE}',\n",
        "        'classes': CLASS_NAMES,\n",
        "        'num_classes': len(CLASS_NAMES),\n",
        "        'trained': datetime.now().isoformat(),\n",
        "        'framework': 'YOLOv8',\n",
        "        'image_size': 640,\n",
        "        'path': final_path,\n",
        "        'size_mb': round(size_mb, 2)\n",
        "    }\n",
        "    \n",
        "    meta_path = os.path.join(MODELS_DIR, 'metadata.json')\n",
        "    with open(meta_path, 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "    \n",
        "    readme = f'''# PPE Detection Model\n",
        "\n",
        "Model: YOLOv8{MODEL_SIZE}\n",
        "Classes: {', '.join(CLASS_NAMES.values())}\n",
        "Size: {size_mb:.2f} MB\n",
        "\n",
        "## Usage\n",
        "\n",
        "Load model:\n",
        "```python\n",
        "from ultralytics import YOLO\n",
        "model = YOLO('best.pt')\n",
        "```\n",
        "\n",
        "Image prediction:\n",
        "```python\n",
        "results = model.predict('image.jpg', conf=0.5)\n",
        "results[0].show()\n",
        "```\n",
        "\n",
        "Video prediction:\n",
        "```python\n",
        "results = model.predict('video.mp4', save=True)\n",
        "```\n",
        "\n",
        "Get detections:\n",
        "```python\n",
        "for box in results[0].boxes:\n",
        "    cls = int(box.cls)\n",
        "    conf = float(box.conf)\n",
        "    print(f\"Class: {{cls}}, Conf: {{conf:.2f}}\")\n",
        "```\n",
        "'''\n",
        "    \n",
        "    with open(os.path.join(MODELS_DIR, 'README.md'), 'w') as f:\n",
        "        f.write(readme)\n",
        "    \n",
        "    print(f\"Metadata: {meta_path}\")\n",
        "    print(f\"README: {os.path.join(MODELS_DIR, 'README.md')}\")\n",
        "else:\n",
        "    print('Trained model not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step10_title",
      "metadata": {},
      "source": [
        "## Step 10: Test on Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "step10",
      "metadata": {},
      "outputs": [],
      "source": [
        "if os.path.exists(final_path):\n",
        "    test_model = YOLO(final_path)\n",
        "    \n",
        "    def predict_image(img_path, conf=0.5):\n",
        "        if not os.path.exists(img_path):\n",
        "            return None\n",
        "        return test_model.predict(\n",
        "            source=img_path,\n",
        "            conf=conf,\n",
        "            imgsz=640,\n",
        "            device=device,\n",
        "            save=True,\n",
        "            project=RESULTS_DIR,\n",
        "            name='predictions'\n",
        "        )\n",
        "    \n",
        "    test_dir = os.path.join(DATASET_PATH, 'images', 'val')\n",
        "    \n",
        "    if os.path.exists(test_dir):\n",
        "        samples = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.png'))][:3]\n",
        "        \n",
        "        if samples:\n",
        "            print(f\"Testing on {len(samples)} images\")\n",
        "            for img in samples:\n",
        "                path = os.path.join(test_dir, img)\n",
        "                results = predict_image(path)\n",
        "                \n",
        "                if results and len(results[0].boxes) > 0:\n",
        "                    print(f\"{img}: {len(results[0].boxes)} detections\")\n",
        "                    for box in results[0].boxes:\n",
        "                        cls = int(box.cls.item())\n",
        "                        conf = box.conf.item()\n",
        "                        name = CLASS_NAMES.get(cls, f'Class{cls}')\n",
        "                        print(f\"  {name}: {conf:.2%}\")\n",
        "                else:\n",
        "                    print(f\"{img}: no detections\")\n",
        "            print(f\"Results: {RESULTS_DIR}/predictions/\")\n",
        "        else:\n",
        "            print('No sample images')\n",
        "    else:\n",
        "        print('Validation directory not found')\n",
        "else:\n",
        "    print('Model not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step11_title",
      "metadata": {},
      "source": [
        "## Step 11: Video Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "step11",
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_video(video_path, output_path, conf=0.5, skip=1, max_frames=None):\n",
        "    if not os.path.exists(video_path):\n",
        "        print('Video not found')\n",
        "        return False\n",
        "    \n",
        "    if not os.path.exists(final_path):\n",
        "        print('Model not found')\n",
        "        return False\n",
        "    \n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print('Cannot open video')\n",
        "        return False\n",
        "    \n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    \n",
        "    print(f\"Video: {w}x{h} @ {fps}fps, {total} frames\")\n",
        "    \n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
        "    \n",
        "    vid_model = YOLO(final_path)\n",
        "    frame_count = 0\n",
        "    detect_count = 0\n",
        "    \n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        \n",
        "        frame_count += 1\n",
        "        \n",
        "        if max_frames and frame_count > max_frames:\n",
        "            break\n",
        "        \n",
        "        if frame_count % skip == 0:\n",
        "            try:\n",
        "                results = vid_model.predict(\n",
        "                    source=frame,\n",
        "                    conf=conf,\n",
        "                    imgsz=640,\n",
        "                    device=device,\n",
        "                    verbose=False\n",
        "                )\n",
        "                frame = results[0].plot()\n",
        "                if len(results[0].boxes) > 0:\n",
        "                    detect_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Error frame {frame_count}: {e}\")\n",
        "        \n",
        "        out.write(frame)\n",
        "        \n",
        "        if frame_count % 30 == 0:\n",
        "            print(f\"Processed {frame_count}/{total}\")\n",
        "    \n",
        "    cap.release()\n",
        "    out.release()\n",
        "    \n",
        "    print(f\"Done: {frame_count} frames, {detect_count} with detections\")\n",
        "    print(f\"Saved: {output_path}\")\n",
        "    return True\n",
        "\n",
        "print('Video processing function ready')\n",
        "print('Usage: process_video(\"input.mp4\", \"output.mp4\", conf=0.5)')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Pipeline complete. Model saved and ready for inference.\n",
        "\n",
        "Download model from:\n",
        "- Kaggle: /kaggle/working/models/ppe/best.pt\n",
        "- Colab: /content/drive/MyDrive/ppe-models/best.pt\n",
        "- Local: ./models/ppe/best.pt"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
