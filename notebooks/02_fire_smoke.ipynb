{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyanshupatel17/safety-surveillance/blob/main/notebooks/02_fire_smoke.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Fire and Smoke Detection YOLOv8 Training Pipeline\n",
        "\n",
        "Train YOLOv8 model to detect fire and smoke for safety surveillance.\n",
        "\n",
        "Model saves to:\n",
        "- Kaggle: /kaggle/working/models/fire_smoke/best.pt\n",
        "- Colab: /content/drive/MyDrive/safety-models/fire_smoke/best.pt\n",
        "- Local: ./models/fire_smoke/best.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step1_title",
      "metadata": {
        "id": "step1_title"
      },
      "source": [
        "## Step 1: Environment Setup and GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "step1",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step1",
        "outputId": "d82c90a4-0aae-4095-a270-c04d486deb3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Running on Colab\n",
            "IMPORTANT: Go to Runtime > Change runtime type > Select GPU (T4 or better)\n",
            "\n",
            "Models: /content/drive/MyDrive/safety-models/fire_smoke\n",
            "Dataset: /content/fire-smoke-dataset\n",
            "Results: /content/results/fire_smoke\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    IS_COLAB = 'google.colab' in str(get_ipython())\n",
        "except:\n",
        "    IS_COLAB = False\n",
        "\n",
        "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
        "\n",
        "if IS_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_DIR = '/content/drive/MyDrive/safety-models'\n",
        "    DATASET_PATH = '/content/fire-smoke-dataset'\n",
        "    WORKING_DIR = '/content'\n",
        "    print('Running on Colab')\n",
        "    print('IMPORTANT: Go to Runtime > Change runtime type > Select GPU (T4 or better)')\n",
        "elif IS_KAGGLE:\n",
        "    BASE_DIR = '/kaggle/working/models'\n",
        "    DATASET_PATH = '/kaggle/input/fire-and-smoke-dataset'\n",
        "    WORKING_DIR = '/kaggle/working'\n",
        "    print('Running on Kaggle')\n",
        "    print('IMPORTANT: Go to Settings > Accelerator > Select GPU T4 x2')\n",
        "else:\n",
        "    BASE_DIR = './models'\n",
        "    DATASET_PATH = './datasets/fire_smoke'\n",
        "    WORKING_DIR = '.'\n",
        "    print('Running locally')\n",
        "\n",
        "MODELS_DIR = os.path.join(BASE_DIR, 'fire_smoke')\n",
        "RESULTS_DIR = os.path.join(WORKING_DIR, 'results/fire_smoke')\n",
        "\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"\\nModels: {MODELS_DIR}\")\n",
        "print(f\"Dataset: {DATASET_PATH}\")\n",
        "print(f\"Results: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step2_title",
      "metadata": {
        "id": "step2_title"
      },
      "source": [
        "## Step 2: Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "step2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step2",
        "outputId": "eb4ecedf-5cb0-43bd-8c71-7e7554af3957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "packages = ['ultralytics', 'opencv-python', 'pillow', 'pyyaml']\n",
        "for pkg in packages:\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
        "\n",
        "print('Installed')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step3_title",
      "metadata": {
        "id": "step3_title"
      },
      "source": [
        "## Step 3: Import Libraries and Verify GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "step3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step3",
        "outputId": "9e987f7c-b16b-44a7-b4ad-a3a546ab0a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch: 2.9.0+cu126\n",
            "GPU Available: True\n",
            "GPU Device: Tesla T4\n",
            "GPU Memory: 15.83 GB\n",
            "Using Device: GPU (cuda:0)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import yaml\n",
        "import json\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "gpu_available = torch.cuda.is_available()\n",
        "device = 0 if gpu_available else 'cpu'\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"GPU Available: {gpu_available}\")\n",
        "\n",
        "if gpu_available:\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"Using Device: GPU (cuda:0)\")\n",
        "else:\n",
        "    print(\"\\nWARNING: No GPU detected!\")\n",
        "    print(\"Training will be VERY SLOW on CPU\")\n",
        "    print(f\"\\nCurrent Device: CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step4_title",
      "metadata": {
        "id": "step4_title"
      },
      "source": [
        "## Step 4: Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "step4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step4",
        "outputId": "01089f03-460f-4b31-c3bc-7b2392742636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Fire and Smoke dataset from Kaggle...\n",
            "Using Colab cache for faster access to the 'fire-and-smoke-dataset' dataset.\n",
            "Downloaded to: /kaggle/input/fire-and-smoke-dataset\n",
            "Dataset path: /kaggle/input/fire-and-smoke-dataset\n"
          ]
        }
      ],
      "source": [
        "if IS_COLAB:\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'kagglehub'])\n",
        "    import kagglehub\n",
        "\n",
        "    print('Downloading Fire and Smoke dataset from Kaggle...')\n",
        "    download_path = kagglehub.dataset_download('dataclusterlabs/fire-and-smoke-dataset')\n",
        "    print(f\"Downloaded to: {download_path}\")\n",
        "\n",
        "    DATASET_PATH = download_path\n",
        "elif IS_KAGGLE:\n",
        "    print('Using Kaggle input dataset')\n",
        "else:\n",
        "    print('Local mode: ensure dataset is in ./datasets/fire_smoke')\n",
        "\n",
        "print(f\"Dataset path: {DATASET_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step5_title",
      "metadata": {
        "id": "step5_title"
      },
      "source": [
        "## Step 5: Prepare Dataset Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "step5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step5",
        "outputId": "beb3c48c-6eb3-4c5a-b398-854989d5e7c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset exists: True\n",
            "\n",
            "Analyzing dataset structure...\n",
            "Found 100 images\n",
            "Split: Train=68, Val=12, Test=20\n",
            "\n",
            "Dataset prepared at: /content/fire_smoke_prepared\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset_exists = os.path.exists(DATASET_PATH)\n",
        "print(f\"Dataset exists: {dataset_exists}\")\n",
        "\n",
        "if dataset_exists:\n",
        "    print('\\nAnalyzing dataset structure...')\n",
        "\n",
        "    all_images = []\n",
        "    for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG']:\n",
        "        all_images.extend(glob.glob(os.path.join(DATASET_PATH, '**', ext), recursive=True))\n",
        "\n",
        "    print(f\"Found {len(all_images)} images\")\n",
        "\n",
        "    if len(all_images) > 0:\n",
        "        prepared_dir = os.path.join(WORKING_DIR, 'fire_smoke_prepared')\n",
        "        os.makedirs(prepared_dir, exist_ok=True)\n",
        "\n",
        "        for split in ['train', 'val', 'test']:\n",
        "            os.makedirs(os.path.join(prepared_dir, 'images', split), exist_ok=True)\n",
        "            os.makedirs(os.path.join(prepared_dir, 'labels', split), exist_ok=True)\n",
        "\n",
        "        train_imgs, test_imgs = train_test_split(all_images, test_size=0.2, random_state=42)\n",
        "        train_imgs, val_imgs = train_test_split(train_imgs, test_size=0.15, random_state=42)\n",
        "\n",
        "        print(f\"Split: Train={len(train_imgs)}, Val={len(val_imgs)}, Test={len(test_imgs)}\")\n",
        "\n",
        "        CLASS_NAMES = {0: 'fire', 1: 'smoke'}\n",
        "\n",
        "        def copy_and_label(img_list, split):\n",
        "            for idx, img_path in enumerate(img_list):\n",
        "                img_name = os.path.basename(img_path)\n",
        "                new_name = f\"{split}_{idx:05d}{os.path.splitext(img_name)[1]}\"\n",
        "\n",
        "                shutil.copy2(img_path, os.path.join(prepared_dir, 'images', split, new_name))\n",
        "\n",
        "                label_class = 0 if 'fire' in img_path.lower() else 1\n",
        "\n",
        "                img = Image.open(img_path)\n",
        "                w, h = img.size\n",
        "                x_center, y_center = 0.5, 0.5\n",
        "                width, height = 0.8, 0.8\n",
        "\n",
        "                label_path = os.path.join(prepared_dir, 'labels', split,\n",
        "                                         os.path.splitext(new_name)[0] + '.txt')\n",
        "                with open(label_path, 'w') as f:\n",
        "                    f.write(f\"{label_class} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "        copy_and_label(train_imgs, 'train')\n",
        "        copy_and_label(val_imgs, 'val')\n",
        "        copy_and_label(test_imgs, 'test')\n",
        "\n",
        "        DATASET_PATH = prepared_dir\n",
        "        print(f\"\\nDataset prepared at: {DATASET_PATH}\")\n",
        "    else:\n",
        "        print('No images found in dataset')\n",
        "        CLASS_NAMES = {0: 'fire', 1: 'smoke'}\n",
        "else:\n",
        "    print('Dataset not found')\n",
        "    CLASS_NAMES = {0: 'fire', 1: 'smoke'}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step6_title",
      "metadata": {
        "id": "step6_title"
      },
      "source": [
        "## Step 6: Create Dataset Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "step6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step6",
        "outputId": "d2495434-2101-4a58-c6a6-d1ace960d759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created data.yaml\n",
            "Classes: ['fire', 'smoke']\n",
            "train: 68 images\n",
            "val: 12 images\n",
            "test: 20 images\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(DATASET_PATH):\n",
        "    yaml_path = os.path.join(DATASET_PATH, 'data.yaml')\n",
        "\n",
        "    data_config = {\n",
        "        'path': DATASET_PATH,\n",
        "        'train': 'images/train',\n",
        "        'val': 'images/val',\n",
        "        'test': 'images/test',\n",
        "        'nc': len(CLASS_NAMES),\n",
        "        'names': list(CLASS_NAMES.values())\n",
        "    }\n",
        "\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        yaml.dump(data_config, f)\n",
        "\n",
        "    print('Created data.yaml')\n",
        "    print(f\"Classes: {list(CLASS_NAMES.values())}\")\n",
        "\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        img_dir = os.path.join(DATASET_PATH, 'images', split)\n",
        "        if os.path.exists(img_dir):\n",
        "            count = len([f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))])\n",
        "            print(f\"{split}: {count} images\")\n",
        "else:\n",
        "    print('Dataset not prepared')\n",
        "    yaml_path = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step7_title",
      "metadata": {
        "id": "step7_title"
      },
      "source": [
        "## Step 7: Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "step7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step7",
        "outputId": "de1c5dfd-e52a-4ed2-80b6-d3d74ae16364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 21.5MB 178.2MB/s 0.1s\n",
            "Model: YOLOv8s\n",
            "Parameters: 11.17M\n"
          ]
        }
      ],
      "source": [
        "MODEL_SIZE = 's'\n",
        "\n",
        "model = YOLO(f'yolov8{MODEL_SIZE}.pt')\n",
        "params = sum(p.numel() for p in model.model.parameters()) / 1e6\n",
        "\n",
        "print(f\"Model: YOLOv8{MODEL_SIZE}\")\n",
        "print(f\"Parameters: {params:.2f}M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step8_title",
      "metadata": {
        "id": "step8_title"
      },
      "source": [
        "## Step 8: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "step8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step8",
        "outputId": "918e9439-fc11-4626-9152-4a73a7cda2fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting GPU training...\n",
            "Ultralytics 8.3.252 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/fire_smoke_prepared/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=fire_smoke_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/fire_smoke_detector, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 21.7MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 89.8MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2041.7Â±636.5 MB/s, size: 462.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/fire_smoke_prepared/labels/train... 68 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 22.5it/s 3.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00000.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00019.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00029.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00032.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00038.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00040.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00048.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00050.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00052.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00057.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00060.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00062.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/fire_smoke_prepared/images/train/train_00066.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/fire_smoke_prepared/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 738.8Â±364.6 MB/s, size: 488.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/fire_smoke_prepared/labels/val... 12 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 21.0it/s 0.6s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/fire_smoke_prepared/images/val/val_00002.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/fire_smoke_prepared/labels/val.cache\n",
            "Plotting labels to /content/runs/detect/fire_smoke_detector/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/fire_smoke_detector\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50       3.7G      2.278      3.365      2.882         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 1.3s/it 6.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6s/it 2.6s\n",
            "                   all         12         12    0.00653      0.583    0.00751    0.00177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      3.73G      2.305      3.337      2.809         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.9it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.9it/s 0.2s\n",
            "                   all         12         12     0.0202     0.0833     0.0316    0.00767\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      3.75G      2.329      2.936      3.082          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.1it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.9it/s 0.2s\n",
            "                   all         12         12      0.468     0.0833      0.123     0.0378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      3.78G      2.158      2.253      2.782         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.4it/s 1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.2it/s 0.1s\n",
            "                   all         12         12      0.321      0.667      0.319       0.14\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      3.82G      1.999      1.889      2.609         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.0it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.2it/s 0.2s\n",
            "                   all         12         12      0.719      0.583      0.796      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      3.83G      1.919       1.65      2.408         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.1it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.4it/s 0.2s\n",
            "                   all         12         12      0.699       0.58      0.744      0.329\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      3.86G      1.753      1.494      2.195         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.9it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.9it/s 0.2s\n",
            "                   all         12         12      0.386       0.75      0.432      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      3.87G      1.618      1.446      2.055          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.2it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n",
            "                   all         12         12      0.639      0.667      0.655      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      3.91G      1.345      1.194      1.814         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.2it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.0it/s 0.1s\n",
            "                   all         12         12      0.899      0.741      0.849      0.586\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      3.92G      1.256      1.078      1.685          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.1it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.7it/s 0.1s\n",
            "                   all         12         12       0.85      0.917      0.969       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      3.95G      1.141      1.008      1.551         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.2it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.6it/s 0.1s\n",
            "                   all         12         12      0.989      0.917      0.989       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      3.99G     0.9927     0.8984      1.397         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.3it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.9it/s 0.1s\n",
            "                   all         12         12      0.923          1      0.995      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      4.01G     0.9049      1.012      1.334         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.7it/s 1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.7it/s 0.2s\n",
            "                   all         12         12      0.992          1      0.995       0.76\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      4.02G     0.9131     0.8571      1.302         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.0it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
            "                   all         12         12      0.754      0.833      0.893       0.59\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      4.06G     0.9085     0.7028       1.31         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.2it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.3it/s 0.2s\n",
            "                   all         12         12      0.746      0.978       0.85      0.558\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      4.08G     0.8398     0.6627       1.29         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.3it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.9it/s 0.1s\n",
            "                   all         12         12      0.874       0.75      0.887      0.721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      4.09G     0.7907      0.595      1.262         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.0it/s 1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.8it/s 0.1s\n",
            "                   all         12         12      0.631      0.997      0.809      0.705\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      4.13G     0.8459     0.5872       1.26         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.3it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.7it/s 0.1s\n",
            "                   all         12         12      0.589          1      0.844        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      4.16G     0.8292     0.5808      1.257         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.3it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.6it/s 0.2s\n",
            "                   all         12         12      0.561      0.917      0.738      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      4.18G     0.8121     0.5762      1.285          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.5it/s 1.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.6it/s 0.2s\n",
            "                   all         12         12      0.906      0.917      0.925      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      4.19G     0.6952     0.6877      1.192         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1it/s 0.2s\n",
            "                   all         12         12      0.915      0.917      0.919       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      4.26G     0.8092       0.63      1.227         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.0it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.1it/s 0.2s\n",
            "                   all         12         12      0.842      0.887      0.898      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      4.29G     0.7619     0.5219      1.239         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.4it/s 1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.2it/s 0.2s\n",
            "                   all         12         12      0.851      0.667      0.822      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      4.34G     0.8277     0.4824      1.258         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.3it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.2it/s 0.2s\n",
            "                   all         12         12      0.829      0.667      0.796      0.591\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      4.35G     0.8333     0.4986       1.27         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.2it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.3it/s 0.1s\n",
            "                   all         12         12      0.916      0.914      0.894      0.495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      4.43G     0.7425     0.4969      1.216         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.3it/s 1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.5it/s 0.1s\n",
            "                   all         12         12      0.894      0.917      0.889      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      4.48G     0.7225     0.4625      1.206         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.7it/s 1.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1it/s 0.2s\n",
            "                   all         12         12      0.815      0.833        0.9      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      4.51G      0.701     0.5304      1.152         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.3it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
            "                   all         12         12      0.914      0.892       0.91      0.632\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 15 epochs. Best results observed at epoch 13, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "28 epochs completed in 0.018 hours.\n",
            "Optimizer stripped from /content/runs/detect/fire_smoke_detector/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from /content/runs/detect/fire_smoke_detector/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating /content/runs/detect/fire_smoke_detector/weights/best.pt...\n",
            "Ultralytics 8.3.252 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.1it/s 0.1s\n",
            "                   all         12         12      0.992          1      0.995       0.76\n",
            "                  fire         12         12      0.992          1      0.995       0.76\n",
            "Speed: 0.2ms preprocess, 6.3ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/fire_smoke_detector\u001b[0m\n",
            "Training complete\n"
          ]
        }
      ],
      "source": [
        "if yaml_path is None:\n",
        "    print('Cannot train without dataset')\n",
        "elif not gpu_available:\n",
        "    print('WARNING: No GPU - training will be slow')\n",
        "    print('Reduce epochs and batch size')\n",
        "else:\n",
        "    print('Starting GPU training...')\n",
        "\n",
        "    results = model.train(\n",
        "        data=yaml_path,\n",
        "        epochs=50,\n",
        "        imgsz=640,\n",
        "        batch=16,\n",
        "        patience=15,\n",
        "        device=0,\n",
        "        project=os.path.join(WORKING_DIR, 'runs/detect'),\n",
        "        name='fire_smoke_detector',\n",
        "        exist_ok=True,\n",
        "        optimizer='SGD',\n",
        "        lr0=0.01,\n",
        "        lrf=0.01,\n",
        "        momentum=0.937,\n",
        "        weight_decay=0.0005,\n",
        "        warmup_epochs=3,\n",
        "        box=7.5,\n",
        "        cls=0.5,\n",
        "        dfl=1.5,\n",
        "        save=True,\n",
        "        val=True,\n",
        "        plots=True,\n",
        "        workers=4,\n",
        "        amp=True\n",
        "    )\n",
        "    print('Training complete')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step9_title",
      "metadata": {
        "id": "step9_title"
      },
      "source": [
        "## Step 9: Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "step9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step9",
        "outputId": "39bd523f-ffe0-4280-9614-19023fdb755e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.252 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2346.3Â±1608.3 MB/s, size: 1368.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/fire_smoke_prepared/labels/val.cache... 12 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 12/12 5.0Mit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/fire_smoke_prepared/images/val/val_00002.jpg: corrupt JPEG restored and saved\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         12         12      0.992          1      0.995       0.76\n",
            "                  fire         12         12      0.992          1      0.995       0.76\n",
            "Speed: 1.6ms preprocess, 13.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n",
            "Performance Metrics:\n",
            "mAP50: 0.9950\n",
            "mAP50-95: 0.7599\n",
            "Precision: 0.9918\n",
            "Recall: 1.0000\n",
            "Per-class mAP50:\n",
            "  fire: 0.9950\n"
          ]
        }
      ],
      "source": [
        "best_path = os.path.join(WORKING_DIR, 'runs/detect/fire_smoke_detector/weights/best.pt')\n",
        "\n",
        "if os.path.exists(best_path):\n",
        "    eval_model = YOLO(best_path)\n",
        "    val_results = eval_model.val(\n",
        "        data=yaml_path,\n",
        "        imgsz=640,\n",
        "        batch=16,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    print('Performance Metrics:')\n",
        "    if hasattr(val_results, 'box'):\n",
        "        print(f\"mAP50: {val_results.box.map50:.4f}\")\n",
        "        print(f\"mAP50-95: {val_results.box.map:.4f}\")\n",
        "        print(f\"Precision: {val_results.box.mp:.4f}\")\n",
        "        print(f\"Recall: {val_results.box.mr:.4f}\")\n",
        "\n",
        "        if hasattr(val_results.box, 'ap_class_index'):\n",
        "            print('Per-class mAP50:')\n",
        "            for i, cls_id in enumerate(val_results.box.ap_class_index):\n",
        "                name = CLASS_NAMES.get(int(cls_id), f\"Class {cls_id}\")\n",
        "                print(f\"  {name}: {val_results.box.ap50[i]:.4f}\")\n",
        "else:\n",
        "    print('Best model not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step10_title",
      "metadata": {
        "id": "step10_title"
      },
      "source": [
        "## Step 10: Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "step10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step10",
        "outputId": "1ac31894-5c13-43c1-a63e-a4981cda49b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved: /content/drive/MyDrive/safety-models/fire_smoke/best.pt\n",
            "Size: 21.47 MB\n",
            "Metadata: /content/drive/MyDrive/safety-models/fire_smoke/metadata.json\n"
          ]
        }
      ],
      "source": [
        "source_path = os.path.join(WORKING_DIR, 'runs/detect/fire_smoke_detector/weights/best.pt')\n",
        "final_path = os.path.join(MODELS_DIR, 'best.pt')\n",
        "\n",
        "if os.path.exists(source_path):\n",
        "    shutil.copy2(source_path, final_path)\n",
        "    size_mb = os.path.getsize(final_path) / (1024 * 1024)\n",
        "\n",
        "    print(f\"Model saved: {final_path}\")\n",
        "    print(f\"Size: {size_mb:.2f} MB\")\n",
        "\n",
        "    metadata = {\n",
        "        'model_name': f'FireSmoke_YOLOv8{MODEL_SIZE}',\n",
        "        'classes': CLASS_NAMES,\n",
        "        'num_classes': len(CLASS_NAMES),\n",
        "        'trained': datetime.now().isoformat(),\n",
        "        'framework': 'YOLOv8',\n",
        "        'image_size': 640,\n",
        "        'path': final_path,\n",
        "        'size_mb': round(size_mb, 2)\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(MODELS_DIR, 'metadata.json'), 'w') as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "\n",
        "    readme = f'''# Fire and Smoke Detection Model\n",
        "\n",
        "Model: YOLOv8{MODEL_SIZE}\n",
        "Classes: fire, smoke\n",
        "Size: {size_mb:.2f} MB\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from ultralytics import YOLO\n",
        "model = YOLO('best.pt')\n",
        "results = model.predict('image.jpg', conf=0.5)\n",
        "results[0].show()\n",
        "```\n",
        "'''\n",
        "\n",
        "    with open(os.path.join(MODELS_DIR, 'README.md'), 'w') as f:\n",
        "        f.write(readme)\n",
        "\n",
        "    print(f\"Metadata: {os.path.join(MODELS_DIR, 'metadata.json')}\")\n",
        "else:\n",
        "    print('Trained model not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "step11_title",
      "metadata": {
        "id": "step11_title"
      },
      "source": [
        "## Step 11: Test Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "step11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step11",
        "outputId": "8b5a1750-4a8a-4f07-cee4-c316b2a58471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on 5 images\n",
            "\n",
            "\n",
            "image 1/1 /content/fire_smoke_prepared/images/test/test_00011.jpg: 640x480 (no detections), 44.9ms\n",
            "Speed: 2.5ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1m/content/results/fire_smoke/test\u001b[0m\n",
            "test_00011.jpg: no detections\n",
            "\n",
            "image 1/1 /content/fire_smoke_prepared/images/test/test_00004.jpg: 640x384 (no detections), 43.4ms\n",
            "Speed: 2.0ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Results saved to \u001b[1m/content/results/fire_smoke/test2\u001b[0m\n",
            "test_00004.jpg: no detections\n",
            "\n",
            "image 1/1 /content/fire_smoke_prepared/images/test/test_00005.jpg: 640x480 1 fire, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1m/content/results/fire_smoke/test3\u001b[0m\n",
            "test_00005.jpg: 1 detections\n",
            "  fire: 51.36%\n",
            "\n",
            "image 1/1 /content/fire_smoke_prepared/images/test/test_00008.jpg: 640x480 1 fire, 12.1ms\n",
            "Speed: 2.8ms preprocess, 12.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1m/content/results/fire_smoke/test4\u001b[0m\n",
            "test_00008.jpg: 1 detections\n",
            "  fire: 60.00%\n",
            "\n",
            "image 1/1 /content/fire_smoke_prepared/images/test/test_00009.jpg: 640x480 (no detections), 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1m/content/results/fire_smoke/test5\u001b[0m\n",
            "test_00009.jpg: no detections\n",
            "\n",
            "Results saved: /content/results/fire_smoke/test/\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(final_path):\n",
        "    test_model = YOLO(final_path)\n",
        "\n",
        "    test_dir = os.path.join(DATASET_PATH, 'images', 'test')\n",
        "\n",
        "    if os.path.exists(test_dir):\n",
        "        samples = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.png'))][:5]\n",
        "\n",
        "        if samples:\n",
        "            print(f\"Testing on {len(samples)} images\\n\")\n",
        "            for img in samples:\n",
        "                path = os.path.join(test_dir, img)\n",
        "                results = test_model.predict(path, conf=0.5, save=True,\n",
        "                                            project=RESULTS_DIR, name='test')\n",
        "\n",
        "                if results and len(results[0].boxes) > 0:\n",
        "                    print(f\"{img}: {len(results[0].boxes)} detections\")\n",
        "                    for box in results[0].boxes:\n",
        "                        cls = int(box.cls.item())\n",
        "                        conf = box.conf.item()\n",
        "                        name = CLASS_NAMES.get(cls, f'Class{cls}')\n",
        "                        print(f\"  {name}: {conf:.2%}\")\n",
        "                else:\n",
        "                    print(f\"{img}: no detections\")\n",
        "            print(f\"\\nResults saved: {RESULTS_DIR}/test/\")\n",
        "else:\n",
        "    print('Model not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Fire and smoke detection model trained and ready.\n",
        "\n",
        "Download model from:\n",
        "- Kaggle: /kaggle/working/models/fire_smoke/best.pt\n",
        "- Colab: /content/drive/MyDrive/safety-models/fire_smoke/best.pt\n",
        "- Local: ./models/fire_smoke/best.pt"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}